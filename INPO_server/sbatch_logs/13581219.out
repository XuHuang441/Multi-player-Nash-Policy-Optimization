no change     /n/sw/Mambaforge-23.11.0-0/condabin/conda
no change     /n/sw/Mambaforge-23.11.0-0/bin/conda
no change     /n/sw/Mambaforge-23.11.0-0/bin/conda-env
no change     /n/sw/Mambaforge-23.11.0-0/bin/activate
no change     /n/sw/Mambaforge-23.11.0-0/bin/deactivate
no change     /n/sw/Mambaforge-23.11.0-0/etc/profile.d/conda.sh
no change     /n/sw/Mambaforge-23.11.0-0/etc/fish/conf.d/conda.fish
no change     /n/sw/Mambaforge-23.11.0-0/shell/condabin/Conda.psm1
no change     /n/sw/Mambaforge-23.11.0-0/shell/condabin/conda-hook.ps1
no change     /n/sw/Mambaforge-23.11.0-0/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /n/sw/Mambaforge-23.11.0-0/etc/profile.d/conda.csh
modified      /n/home08/xiaominli/.bashrc

==> For changes to take effect, close and re-open your current shell. <==

Added mamba to /n/home08/xiaominli/.bashrc

==> For changes to take effect, close and re-open your current shell. <==

INFO 05-03 06:42:03 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 06:42:03 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 06:42:03 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 06:42:03 [__init__.py:239] Automatically detected platform cuda.
model_path RLHFlow/LLaMA3-SFT
Dataset_path RLHFlow/iterative-prompt-v1-iter1-20K
INFO 05-03 06:43:15 [config.py:689] This model supports multiple tasks: {'classify', 'score', 'reward', 'generate', 'embed'}. Defaulting to 'generate'.
model_path RLHFlow/LLaMA3-SFT
Dataset_path RLHFlow/iterative-prompt-v1-iter1-20K
INFO 05-03 06:43:15 [config.py:689] This model supports multiple tasks: {'reward', 'classify', 'embed', 'score', 'generate'}. Defaulting to 'generate'.
model_path RLHFlow/LLaMA3-SFT
Dataset_path RLHFlow/iterative-prompt-v1-iter1-20K
INFO 05-03 06:43:15 [config.py:689] This model supports multiple tasks: {'score', 'classify', 'embed', 'reward', 'generate'}. Defaulting to 'generate'.
model_path RLHFlow/LLaMA3-SFT
Dataset_path RLHFlow/iterative-prompt-v1-iter1-20K
INFO 05-03 06:43:15 [config.py:689] This model supports multiple tasks: {'embed', 'reward', 'score', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 05-03 06:43:15 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-03 06:43:15 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-03 06:43:15 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-03 06:43:15 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-03 06:43:22 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='RLHFlow/LLaMA3-SFT', speculative_config=None, tokenizer='RLHFlow/LLaMA3-SFT', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=RLHFlow/LLaMA3-SFT, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 05-03 06:43:22 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='RLHFlow/LLaMA3-SFT', speculative_config=None, tokenizer='RLHFlow/LLaMA3-SFT', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=RLHFlow/LLaMA3-SFT, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 05-03 06:43:22 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='RLHFlow/LLaMA3-SFT', speculative_config=None, tokenizer='RLHFlow/LLaMA3-SFT', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=RLHFlow/LLaMA3-SFT, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 05-03 06:43:22 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='RLHFlow/LLaMA3-SFT', speculative_config=None, tokenizer='RLHFlow/LLaMA3-SFT', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=RLHFlow/LLaMA3-SFT, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 05-03 06:43:40 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14bcda9db490>
WARNING 05-03 06:43:40 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14ca1111fa90>
WARNING 05-03 06:43:40 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14c2466df7d0>
WARNING 05-03 06:43:40 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1474bcb7f1d0>
INFO 05-03 06:43:43 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-03 06:43:43 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-03 06:43:43 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-03 06:43:43 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-03 06:43:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-03 06:43:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-03 06:43:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-03 06:43:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-03 06:43:43 [gpu_model_runner.py:1276] Starting to load model RLHFlow/LLaMA3-SFT...
INFO 05-03 06:43:43 [gpu_model_runner.py:1276] Starting to load model RLHFlow/LLaMA3-SFT...
INFO 05-03 06:43:43 [gpu_model_runner.py:1276] Starting to load model RLHFlow/LLaMA3-SFT...
INFO 05-03 06:43:43 [gpu_model_runner.py:1276] Starting to load model RLHFlow/LLaMA3-SFT...
WARNING 05-03 06:43:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
WARNING 05-03 06:43:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
WARNING 05-03 06:43:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
WARNING 05-03 06:43:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 05-03 06:43:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
INFO 05-03 06:43:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
INFO 05-03 06:43:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
INFO 05-03 06:43:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
INFO 05-03 06:44:10 [loader.py:458] Loading weights took 24.69 seconds
INFO 05-03 06:44:10 [loader.py:458] Loading weights took 24.61 seconds
INFO 05-03 06:44:10 [loader.py:458] Loading weights took 24.89 seconds
INFO 05-03 06:44:10 [loader.py:458] Loading weights took 24.49 seconds
INFO 05-03 06:44:10 [gpu_model_runner.py:1291] Model loading took 14.9596 GiB and 26.448403 seconds
INFO 05-03 06:44:10 [gpu_model_runner.py:1291] Model loading took 14.9596 GiB and 26.420450 seconds
INFO 05-03 06:44:10 [gpu_model_runner.py:1291] Model loading took 14.9596 GiB and 26.471873 seconds
INFO 05-03 06:44:11 [gpu_model_runner.py:1291] Model loading took 14.9596 GiB and 26.485246 seconds
INFO 05-03 06:45:20 [backends.py:416] Using cache directory: /n/home08/xiaominli/.cache/vllm/torch_compile_cache/da22a90462/rank_0_0 for vLLM's torch.compile
INFO 05-03 06:45:20 [backends.py:416] Using cache directory: /n/home08/xiaominli/.cache/vllm/torch_compile_cache/da22a90462/rank_0_0 for vLLM's torch.compile
INFO 05-03 06:45:20 [backends.py:416] Using cache directory: /n/home08/xiaominli/.cache/vllm/torch_compile_cache/da22a90462/rank_0_0 for vLLM's torch.compile
INFO 05-03 06:45:20 [backends.py:416] Using cache directory: /n/home08/xiaominli/.cache/vllm/torch_compile_cache/da22a90462/rank_0_0 for vLLM's torch.compile
INFO 05-03 06:45:20 [backends.py:426] Dynamo bytecode transform time: 69.63 s
INFO 05-03 06:45:20 [backends.py:426] Dynamo bytecode transform time: 69.62 s
INFO 05-03 06:45:20 [backends.py:426] Dynamo bytecode transform time: 69.66 s
INFO 05-03 06:45:20 [backends.py:426] Dynamo bytecode transform time: 69.68 s
INFO 05-03 06:45:23 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 05-03 06:45:23 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 05-03 06:45:23 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 05-03 06:45:23 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 05-03 06:45:50 [monitor.py:33] torch.compile takes 69.66 s in total
INFO 05-03 06:45:51 [monitor.py:33] torch.compile takes 69.62 s in total
INFO 05-03 06:45:51 [monitor.py:33] torch.compile takes 69.63 s in total
INFO 05-03 06:45:52 [monitor.py:33] torch.compile takes 69.68 s in total
INFO 05-03 06:45:56 [kv_cache_utils.py:634] GPU KV cache size: 446,560 tokens
INFO 05-03 06:45:56 [kv_cache_utils.py:637] Maximum concurrency for 8,192 tokens per request: 54.51x
INFO 05-03 06:45:56 [kv_cache_utils.py:634] GPU KV cache size: 446,560 tokens
INFO 05-03 06:45:56 [kv_cache_utils.py:637] Maximum concurrency for 8,192 tokens per request: 54.51x
INFO 05-03 06:45:56 [kv_cache_utils.py:634] GPU KV cache size: 446,560 tokens
INFO 05-03 06:45:56 [kv_cache_utils.py:637] Maximum concurrency for 8,192 tokens per request: 54.51x
INFO 05-03 06:45:56 [kv_cache_utils.py:634] GPU KV cache size: 446,560 tokens
INFO 05-03 06:45:56 [kv_cache_utils.py:637] Maximum concurrency for 8,192 tokens per request: 54.51x
INFO 05-03 06:47:10 [gpu_model_runner.py:1626] Graph capturing finished in 74 secs, took 0.52 GiB
INFO 05-03 06:47:10 [gpu_model_runner.py:1626] Graph capturing finished in 74 secs, took 0.52 GiB
INFO 05-03 06:47:10 [gpu_model_runner.py:1626] Graph capturing finished in 74 secs, took 0.52 GiB
INFO 05-03 06:47:10 [gpu_model_runner.py:1626] Graph capturing finished in 74 secs, took 0.52 GiB
INFO 05-03 06:47:10 [core.py:163] init engine (profile, create kv cache, warmup model) took 179.49 seconds
INFO 05-03 06:47:10 [core.py:163] init engine (profile, create kv cache, warmup model) took 179.50 seconds
INFO 05-03 06:47:10 [core.py:163] init engine (profile, create kv cache, warmup model) took 179.46 seconds
INFO 05-03 06:47:10 [core.py:163] init engine (profile, create kv cache, warmup model) took 179.52 seconds
INFO 05-03 06:47:10 [core_client.py:435] Core engine process 0 ready.
INFO 05-03 06:47:10 [core_client.py:435] Core engine process 0 ready.
INFO 05-03 06:47:10 [core_client.py:435] Core engine process 0 ready.
INFO 05-03 06:47:10 [core_client.py:435] Core engine process 0 ready.
Data Size:20000
Data Size:20000
Data Size:20000
Data Size:20000
I collect  5000 samples
Saving output to: dataset_path/datasets/inpo_iter1/data_2.json
I collect  5000 samples
Saving output to: dataset_path/datasets/inpo_iter1/data_1.json
I collect  5000 samples
Saving output to: dataset_path/datasets/inpo_iter1/data_3.json
I collect  5000 samples
Saving output to: dataset_path/datasets/inpo_iter1/data_0.json
dataset_path/datasets/inpo_iter1/data_0.json
5000
dataset_path/datasets/inpo_iter1/data_1.json
5000
dataset_path/datasets/inpo_iter1/data_2.json
5000
dataset_path/datasets/inpo_iter1/data_3.json
5000
I collect  20000 samples
dataset_path/datasets/inpo_iter1/data.json
[2025-05-03 08:37:24,012] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 08:37:24,013] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 08:37:24,014] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 08:37:24,018] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
5000
5000
5000
5000
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
we don't know which one is better
dataset_path/datasets/inpo_iter1/pref_0.json
4922
dataset_path/datasets/inpo_iter1/pref_1.json
4907
dataset_path/datasets/inpo_iter1/pref_2.json
4915
dataset_path/datasets/inpo_iter1/pref_3.json
4911
I collect  19655 samples
dataset_path/datasets/inpo_iter1/pref_data.json
[2025-05-03 19:12:59,437] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 19:13:44,725] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 19:13:44,744] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 19:13:44,748] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 19:13:44,759] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Tie 0 samples
[2025-05-03 19:14:17,642] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-03 19:14:17,642] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Tie 0 samples
Tie 0 samples
[2025-05-03 19:14:17,702] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-03 19:14:17,721] [INFO] [comm.py:669:init_distributed] cdb=None
Tie 0 samples
[2025-05-03 19:14:17,779] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-03 19:15:17,917] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.7, git-hash=unknown, git-branch=unknown
[2025-05-03 19:15:17,917] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-05-03 19:18:08,787] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-05-03 19:18:11,584] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-05-03 19:18:12,016] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-05-03 19:18:33,788] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-05-03 19:18:33,790] [INFO] [logging.py:107:log_dist] [Rank 0] Creating BF16 optimizer
begin to precompute
begin to precompute
begin to precompute
[2025-05-03 19:18:34,099] [INFO] [utils.py:781:see_memory_usage] begin bf16_optimizer
[2025-05-03 19:18:34,099] [INFO] [utils.py:782:see_memory_usage] MA 14.96 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB 
[2025-05-03 19:18:34,100] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 14.66 GB, percent = 2.9%
[2025-05-03 19:18:34,295] [INFO] [utils.py:781:see_memory_usage] end bf16_ optimizer
[2025-05-03 19:18:34,295] [INFO] [utils.py:782:see_memory_usage] MA 14.96 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB 
[2025-05-03 19:18:34,296] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 14.66 GB, percent = 2.9%
[2025-05-03 19:18:34,296] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   amp_enabled .................. False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   amp_params ................... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1526fba76c10>
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   communication_data_type ...... None
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   disable_allgather ............ False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   dump_state ................... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   global_rank .................. 0
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 1
[2025-05-03 19:18:34,297] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   optimizer_name ............... None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   optimizer_params ............. None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   pld_enabled .................. False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   pld_params ................... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   scheduler_name ............... None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   scheduler_params ............. None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   sparse_attention ............. None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   steps_per_print .............. inf
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   train_batch_size ............. 4
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  1
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   world_size ................... 4
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   zero_enabled ................. False
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[2025-05-03 19:18:34,298] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 0
[2025-05-03 19:18:34,298] [INFO] [config.py:993:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
begin to precompute
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
(19655,) (19655,)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-05-03 20:11:56,394] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:12:36,839] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:12:36,846] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:12:36,853] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:12:36,857] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Merging deepspeed checkpoints...
INFO 05-03 20:14:20 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:14:20 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:14:20 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:14:20 [__init__.py:239] Automatically detected platform cuda.
model_path model_path/models/inpo_iter1
Dataset_path RLHFlow/iterative-prompt-v1-iter2-20K
model_path model_path/models/inpo_iter1
Dataset_path RLHFlow/iterative-prompt-v1-iter2-20K
model_path model_path/models/inpo_iter1
Dataset_path RLHFlow/iterative-prompt-v1-iter2-20K
model_path model_path/models/inpo_iter1
Dataset_path RLHFlow/iterative-prompt-v1-iter2-20K
dataset_path/datasets/inpo_iter2/data_0.json
[2025-05-03 20:15:32,734] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:15:32,740] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:15:32,748] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:15:32,752] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
dataset_path/datasets/inpo_iter2/pref_0.json
[2025-05-03 20:16:46,632] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:17:24,812] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:17:24,832] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:17:24,839] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:17:24,853] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-05-03 20:18:10,008] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:18:49,391] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:18:49,397] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:18:49,441] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:18:49,446] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Merging deepspeed checkpoints...
INFO 05-03 20:19:44 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:19:45 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:19:45 [__init__.py:239] Automatically detected platform cuda.
INFO 05-03 20:19:45 [__init__.py:239] Automatically detected platform cuda.
model_path model_path/models/inpo_iter2
Dataset_path RLHFlow/iterative-prompt-v1-iter3-20K
model_path model_path/models/inpo_iter2
Dataset_path RLHFlow/iterative-prompt-v1-iter3-20K
model_path model_path/models/inpo_iter2
Dataset_path RLHFlow/iterative-prompt-v1-iter3-20K
model_path model_path/models/inpo_iter2
Dataset_path RLHFlow/iterative-prompt-v1-iter3-20K
dataset_path/datasets/inpo_iter3/data_0.json
[2025-05-03 20:20:32,335] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:20:32,336] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:20:32,343] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:20:32,362] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
dataset_path/datasets/inpo_iter3/pref_0.json
[2025-05-03 20:21:26,725] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:22:03,477] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:22:03,501] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:22:03,502] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:22:03,526] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-05-03 20:22:48,241] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:23:25,879] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:23:25,881] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:23:25,974] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-03 20:23:25,998] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/netscratch/lu_lab/Lab/xiaominli/mycache/triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Merging deepspeed checkpoints...
